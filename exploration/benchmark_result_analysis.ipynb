{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c2e01ee1",
   "metadata": {},
   "source": [
    "# IMPORTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dcc23294",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "07267343",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append(\"./..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bcf358bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils.dspy_templates as dspy_templates\n",
    "import utils.outputs as outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4637513d",
   "metadata": {},
   "source": [
    "### _ENV vars_\n",
    "Set the location of your local `.env` file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "af425c05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import dotenv\n",
    "\n",
    "dotenv.load_dotenv(dotenv_path=\"../.env\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee98a48a",
   "metadata": {},
   "source": [
    "# DATA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f908856",
   "metadata": {},
   "source": [
    "### _Golden Dataset_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f0d6cc39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 3)\n"
     ]
    }
   ],
   "source": [
    "GOLDEN_DATASET_PATH = \"../dataset/arithmetic_expressions_golden_dataset.parquet\"\n",
    "\n",
    "expressions = pandas.read_parquet(path=GOLDEN_DATASET_PATH)\n",
    "\n",
    "print(expressions.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47959053",
   "metadata": {},
   "source": [
    "### _Model selection among all available results_\n",
    "A 'model' consists in a **language model** and a **defined prompt**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e0151fbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "RESULT_PATH = os.getenv(\"RESULT_PATH\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2a59e6cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original\n",
      "student-LocalSmolLM135m-teacher-LocalSmolLM135m\n",
      "student-LocalSmolLM135m-teacher-gpt-4.1\n",
      "student-gpt-4.1-nano-teacher-gpt-4.1\n",
      "student-gpt-4.1-nano-teacher-gpt-4.1-nano\n",
      "student-gpt-4.1-teacher-gpt-4.1\n"
     ]
    }
   ],
   "source": [
    "for folder in sorted(os.listdir(RESULT_PATH)):\n",
    "    print(folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b4c6d8cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LocalSmolLM135m\n",
      "gpt-4.1-nano\n",
      "gpt-4.1\n"
     ]
    }
   ],
   "source": [
    "PROMPT_NAME = \"original\"\n",
    "\n",
    "AVAILABLE_RESULTS = RESULT_PATH + \"/\" + PROMPT_NAME + \"/\" + \"results\" + \"/\"\n",
    "\n",
    "for folder in sorted(os.listdir(AVAILABLE_RESULTS)):\n",
    "    print(folder.split(\".parquet\")[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "38cec39a",
   "metadata": {},
   "outputs": [],
   "source": [
    "RESULT_NAME = \"LocalSmolLM135m\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2df90798",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result DataFrame has 100 rows and 3 columns.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>process_error</th>\n",
       "      <th>raw_result</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>```python\\n# Define the arithmetic expression\\nar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>```python\\n# Define the arithmetic expression\\nar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>None</td>\n",
       "      <td>```python\\ndef arithmetic_expression(arithmetic</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id process_error                                         raw_result\n",
       "0   0          None  ```python\\n# Define the arithmetic expression\\nar\n",
       "1   1          None  ```python\\n# Define the arithmetic expression\\nar\n",
       "2   2          None    ```python\\ndef arithmetic_expression(arithmetic"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "results = pandas.read_parquet(path=AVAILABLE_RESULTS + RESULT_NAME + \".parquet\")\n",
    "\n",
    "print(f\"Result DataFrame has {results.shape[0]} rows and {results.shape[1]} columns.\")\n",
    "display(results.head(n=3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7a0bfda",
   "metadata": {},
   "source": [
    "# EXPLORATION"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bec3bd3d",
   "metadata": {},
   "source": [
    "### _Errors in LM responses_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "40e5c845",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response error count = 0\n"
     ]
    }
   ],
   "source": [
    "nb_errors_in_responses = results[\"process_error\"].notna().sum()\n",
    "print(f\"Response error count = {nb_errors_in_responses}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "21a40765",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'```python\\n# Define the arithmetic expression\\nar'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.iloc[0][\"raw_result\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a08b3be",
   "metadata": {},
   "source": [
    "### _Merging responses with original golden dataset (ground truth)_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6e25f560",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 5)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>expression</th>\n",
       "      <th>actual_result</th>\n",
       "      <th>process_error</th>\n",
       "      <th>raw_result</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>((3 + 5 * (8 - 4)) / (6 + 2)) * (7 - 2)</td>\n",
       "      <td>14.375</td>\n",
       "      <td>None</td>\n",
       "      <td>```python\\n# Define the arithmetic expression\\nar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>(((9 + 3) * (6 - 2)) / 4) + (15 / (5 + 5))</td>\n",
       "      <td>13.500</td>\n",
       "      <td>None</td>\n",
       "      <td>```python\\n# Define the arithmetic expression\\nar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>((8 * (3 + 5)) - (20 / (4 + 1))) * (2 + 3)</td>\n",
       "      <td>300.000</td>\n",
       "      <td>None</td>\n",
       "      <td>```python\\ndef arithmetic_expression(arithmetic</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                  expression  actual_result  \\\n",
       "0   0     ((3 + 5 * (8 - 4)) / (6 + 2)) * (7 - 2)         14.375   \n",
       "1   1  (((9 + 3) * (6 - 2)) / 4) + (15 / (5 + 5))         13.500   \n",
       "2   2  ((8 * (3 + 5)) - (20 / (4 + 1))) * (2 + 3)        300.000   \n",
       "\n",
       "  process_error                                         raw_result  \n",
       "0          None  ```python\\n# Define the arithmetic expression\\nar  \n",
       "1          None  ```python\\n# Define the arithmetic expression\\nar  \n",
       "2          None    ```python\\ndef arithmetic_expression(arithmetic  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "retrieved_results = pandas.merge(\n",
    "    expressions.rename(columns={\"result\": \"actual_result\"}),\n",
    "    results.loc[results[\"process_error\"].isna()],\n",
    "    on=\"id\",\n",
    "    how=\"inner\",\n",
    ")\n",
    "\n",
    "print(retrieved_results.shape)\n",
    "display(retrieved_results.head(n=3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94089026",
   "metadata": {},
   "source": [
    "### _Process raw responses_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "667d65c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_float_result_or_error(row: pandas.Series):\n",
    "    result = row[\"raw_result\"]\n",
    "    try:\n",
    "        result = dspy_templates.get_result_from_dspy_template(\n",
    "            result=result, final_strip=True\n",
    "        )\n",
    "        result = outputs.string_result_to_numeric(result=result)\n",
    "        return {\"inferred_result\": result, \"inference_error\": False}\n",
    "    except:\n",
    "        return {\"inferred_result\": result, \"inference_error\": True}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cb604cc3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Error in output format</th>\n",
       "      <th>Yes</th>\n",
       "      <th>No</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Error in output format  Yes  No\n",
       "count                   100   0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "retrieved_results[[\"inferred_result\", \"inference_error\"]] = retrieved_results.apply(\n",
    "    get_float_result_or_error, axis=1, result_type=\"expand\"\n",
    ")\n",
    "\n",
    "display(\n",
    "    retrieved_results[\"inference_error\"]\n",
    "    .rename(\"Error in output format\")\n",
    "    .value_counts(dropna=False, normalize=False)\n",
    "    .reindex([True, False])\n",
    "    .fillna(0)\n",
    "    .rename({True: \"Yes\", False: \"No\"})\n",
    "    .astype(int)\n",
    "    .to_frame()\n",
    "    .transpose()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "79485428",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 7)\n"
     ]
    }
   ],
   "source": [
    "correctly_inferred_results = retrieved_results.loc[\n",
    "    ~retrieved_results[\"inference_error\"]\n",
    "]\n",
    "\n",
    "print(correctly_inferred_results.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0cecd882",
   "metadata": {},
   "outputs": [],
   "source": [
    "correctly_inferred_results[\"actual_result\"] = correctly_inferred_results[\n",
    "    \"actual_result\"\n",
    "].astype(float)\n",
    "correctly_inferred_results[\"inferred_result\"] = correctly_inferred_results[\n",
    "    \"inferred_result\"\n",
    "].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4b0ead91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>expression</th>\n",
       "      <th>actual_result</th>\n",
       "      <th>process_error</th>\n",
       "      <th>raw_result</th>\n",
       "      <th>inferred_result</th>\n",
       "      <th>inference_error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [id, expression, actual_result, process_error, raw_result, inferred_result, inference_error]\n",
       "Index: []"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(correctly_inferred_results.head(n=3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0f85748",
   "metadata": {},
   "source": [
    "### _Metrics_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f70f120d",
   "metadata": {},
   "source": [
    "##### Global metrics from raw output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "36c9d8b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(df: pandas.DataFrame):\n",
    "    return (df[\"actual_result\"] == df[\"inferred_result\"]).sum() / df.shape[0]\n",
    "\n",
    "\n",
    "def mape(df: pandas.DataFrame):\n",
    "    return (\n",
    "        (df[\"actual_result\"] - df[\"inferred_result\"]).abs() / abs(df[\"actual_result\"])\n",
    "    ).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e7887d30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No correctly inferred results, thus no metrics can be computed.\n"
     ]
    }
   ],
   "source": [
    "if correctly_inferred_results.shape[0] > 0:\n",
    "    print(f\"Accuracy = {accuracy(df=correctly_inferred_results)* 100:.1f}%\")\n",
    "    print(f\"MAPE = {mape(df=correctly_inferred_results)*100:.1f}%\")\n",
    "else:\n",
    "    print(\"No correctly inferred results, thus no metrics can be computed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82d12d1c",
   "metadata": {},
   "source": [
    "##### Global metrics using `DSPy`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "55359641",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "with open(\n",
    "    RESULT_PATH\n",
    "    + \"/\"\n",
    "    + PROMPT_NAME\n",
    "    + \"/\"\n",
    "    + \"metrics\"\n",
    "    + \"/\"\n",
    "    + \"dspy\"\n",
    "    + \"/\"\n",
    "    + RESULT_NAME\n",
    "    + \".json\",\n",
    "    \"r\",\n",
    ") as json_file:\n",
    "    dspy_metrics = json.load(json_file)\n",
    "\n",
    "print(len(dspy_metrics))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "80e51323",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "binary_accuracy_metrics = 6.0%\n",
      "mape_metrics = 63.74%\n"
     ]
    }
   ],
   "source": [
    "for metrics in dspy_metrics:\n",
    "    print(f\"{metrics} = {dspy_metrics[metrics]}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce0da70b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_auto_prompt_improver",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
